import { useState, useEffect, useRef } from 'react';
import { useNavigate } from 'react-router-dom';
import './DrumKit.css';

function DrumKit() {
  const navigate = useNavigate();
  const [isRecording, setIsRecording] = useState(false);
  const [recordedBeats, setRecordedBeats] = useState([]);
  const [isPlaying, setIsPlaying] = useState(false);
  const [bpm, setBpm] = useState(120);
  const [metronomeActive, setMetronomeActive] = useState(false);
  const [isExporting, setIsExporting] = useState(false);
  const [exportFormat, setExportFormat] = useState('webm');
  const recordingStartTime = useRef(null);
  const metronomeInterval = useRef(null);
  const audioContextRef = useRef(null);

  const drums = [
    { id: 'kick', name: 'Kick', key: 'A', color: '#ff6b9d' },
    { id: 'snare', name: 'Snare', key: 'S', color: '#ff9d6b' },
    { id: 'hihat', name: 'Hi-Hat', key: 'D', color: '#ffd700' },
    { id: 'tom1', name: 'Tom 1', key: 'F', color: '#00d4ff' },
    { id: 'tom2', name: 'Tom 2', key: 'G', color: '#9d6bff' },
    { id: 'crash', name: 'Crash', key: 'H', color: '#6bff9d' },
    { id: 'ride', name: 'Ride', key: 'J', color: '#ff6bf0' },
    { id: 'clap', name: 'Clap', key: 'K', color: '#6bd4ff' },
  ];

  const getAudioContext = () => {
    if (!audioContextRef.current) {
      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
    }
    return audioContextRef.current;
  };

  const playSound = (drumId) => {
    const audioContext = getAudioContext();
    const oscillator = audioContext.createOscillator();
    const gainNode = audioContext.createGain();

    const soundMap = {
      kick: { freq: 150, duration: 0.5, type: 'sine' },
      snare: { freq: 200, duration: 0.2, type: 'triangle' },
      hihat: { freq: 8000, duration: 0.05, type: 'square' },
      tom1: { freq: 220, duration: 0.3, type: 'sine' },
      tom2: { freq: 180, duration: 0.3, type: 'sine' },
      crash: { freq: 5000, duration: 0.8, type: 'sawtooth' },
      ride: { freq: 3000, duration: 0.4, type: 'square' },
      clap: { freq: 1000, duration: 0.1, type: 'white-noise' }
    };

    const sound = soundMap[drumId];
    oscillator.frequency.value = sound.freq;
    oscillator.type = sound.type === 'white-noise' ? 'square' : sound.type;

    gainNode.gain.setValueAtTime(0.3, audioContext.currentTime);
    gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + sound.duration);

    oscillator.connect(gainNode);
    gainNode.connect(audioContext.destination);

    oscillator.start();
    oscillator.stop(audioContext.currentTime + sound.duration);

    if (isRecording) {
      const timestamp = Date.now() - recordingStartTime.current;
      setRecordedBeats(prev => [...prev, { drumId, timestamp }]);
    }
  };

  const exportRecording = async () => {
    if (recordedBeats.length === 0) return;
    
    setIsExporting(true);
    
    try {
      if (exportFormat === 'wav') {
        await exportAsWAV();
      } else {
        await exportAsWebM();
      }
    } catch (error) {
      console.error('Export failed:', error);
      alert('å¯¼å‡ºå¤±è´¥ï¼Œè¯·é‡è¯•');
    }
    
    setIsExporting(false);
  };

  const exportAsWebM = async () => {
    // åˆ›å»ºä¸€ä¸ªæ–°çš„AudioContextç”¨äºå¯¼å‡º
    const exportContext = new (window.AudioContext || window.webkitAudioContext)();
    const destination = exportContext.createMediaStreamDestination();
    
    // å°è¯•ä¸åŒçš„MIMEç±»å‹
    let mimeType = 'audio/webm';
    if (exportFormat === 'mp3' && MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
      mimeType = 'audio/webm;codecs=opus';
    } else if (exportFormat === 'ogg' && MediaRecorder.isTypeSupported('audio/ogg;codecs=opus')) {
      mimeType = 'audio/ogg;codecs=opus';
    }
    
    // è®¾ç½®MediaRecorder
    const mediaRecorder = new MediaRecorder(destination.stream, { mimeType });
    const chunks = [];
    
    mediaRecorder.ondataavailable = (e) => {
      if (e.data.size > 0) {
        chunks.push(e.data);
      }
    };
    
    // åˆ›å»ºPromiseç­‰å¾…å½•åˆ¶å®Œæˆ
    const recordingComplete = new Promise((resolve) => {
      mediaRecorder.onstop = () => {
        const blob = new Blob(chunks, { type: mimeType });
        resolve(blob);
      }
    });
    
    // å¼€å§‹å½•åˆ¶
    mediaRecorder.start();
    
    // æ’­æ”¾å½•åˆ¶çš„èŠ‚å¥
    for (const beat of recordedBeats) {
      await new Promise(resolve => setTimeout(resolve, beat.timestamp));
      
      // åˆ›å»ºå¹¶æ’­æ”¾å£°éŸ³
      const oscillator = exportContext.createOscillator();
      const gainNode = exportContext.createGain();
      
      const soundMap = {
        kick: { freq: 150, duration: 0.5, type: 'sine' },
        snare: { freq: 200, duration: 0.2, type: 'triangle' },
        hihat: { freq: 8000, duration: 0.1, type: 'square' },
        tom1: { freq: 220, duration: 0.3, type: 'sine' },
        tom2: { freq: 180, duration: 0.3, type: 'sine' },
        crash: { freq: 5000, duration: 0.5, type: 'square' },
        ride: { freq: 3000, duration: 0.3, type: 'triangle' },
        clap: { freq: 1000, duration: 0.1, type: 'square' },
      };
      
      const sound = soundMap[beat.drumId];
      oscillator.type = sound.type;
      oscillator.frequency.value = sound.freq;
      
      gainNode.gain.setValueAtTime(0.5, exportContext.currentTime);
      gainNode.gain.exponentialRampToValueAtTime(0.01, exportContext.currentTime + sound.duration);
      
      oscillator.connect(gainNode);
      gainNode.connect(destination);
      
      oscillator.start();
      oscillator.stop(exportContext.currentTime + sound.duration);
    }
    
    // ç­‰å¾…æœ€åä¸€ä¸ªå£°éŸ³ç»“æŸ
    const lastBeat = recordedBeats[recordedBeats.length - 1];
    const soundMap = {
      kick: { duration: 0.5 },
      snare: { duration: 0.2 },
      hihat: { duration: 0.1 },
      tom1: { duration: 0.3 },
      tom2: { duration: 0.3 },
      crash: { duration: 0.5 },
      ride: { duration: 0.3 },
      clap: { duration: 0.1 },
    };
    const lastDuration = soundMap[lastBeat.drumId].duration;
    await new Promise(resolve => setTimeout(resolve, lastDuration * 1000 + 500));
    
    // åœæ­¢å½•åˆ¶
    mediaRecorder.stop();
    
    // ç­‰å¾…å½•åˆ¶å®Œæˆ
    const blob = await recordingComplete;
    
    // ä¸‹è½½æ–‡ä»¶
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `drum-recording-${Date.now()}.${exportFormat}`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
    
    // å…³é—­å¯¼å‡ºç”¨çš„AudioContext
    exportContext.close();
  };

  const exportAsWAV = async () => {
    // è®¡ç®—æ€»æ—¶é•¿
    const lastBeat = recordedBeats[recordedBeats.length - 1];
    const soundMap = {
      kick: { duration: 0.5 },
      snare: { duration: 0.2 },
      hihat: { duration: 0.1 },
      tom1: { duration: 0.3 },
      tom2: { duration: 0.3 },
      crash: { duration: 0.5 },
      ride: { duration: 0.3 },
      clap: { duration: 0.1 },
    };
    const lastDuration = soundMap[lastBeat.drumId].duration;
    const totalDuration = (lastBeat.timestamp + lastDuration * 1000 + 500) / 1000;
    
    // ä½¿ç”¨OfflineAudioContextæ¸²æŸ“
    const sampleRate = 48000;
    const offlineContext = new OfflineAudioContext(2, sampleRate * totalDuration, sampleRate);
    
    // æ’­æ”¾æ‰€æœ‰å½•åˆ¶çš„èŠ‚æ‹
    for (const beat of recordedBeats) {
      const startTime = beat.timestamp / 1000;
      
      const oscillator = offlineContext.createOscillator();
      const gainNode = offlineContext.createGain();
      
      const fullSoundMap = {
        kick: { freq: 150, duration: 0.5, type: 'sine' },
        snare: { freq: 200, duration: 0.2, type: 'triangle' },
        hihat: { freq: 8000, duration: 0.1, type: 'square' },
        tom1: { freq: 220, duration: 0.3, type: 'sine' },
        tom2: { freq: 180, duration: 0.3, type: 'sine' },
        crash: { freq: 5000, duration: 0.5, type: 'square' },
        ride: { freq: 3000, duration: 0.3, type: 'triangle' },
        clap: { freq: 1000, duration: 0.1, type: 'square' },
      };
      
      const sound = fullSoundMap[beat.drumId];
      oscillator.type = sound.type;
      oscillator.frequency.value = sound.freq;
      
      gainNode.gain.setValueAtTime(0.5, startTime);
      gainNode.gain.exponentialRampToValueAtTime(0.01, startTime + sound.duration);
      
      oscillator.connect(gainNode);
      gainNode.connect(offlineContext.destination);
      
      oscillator.start(startTime);
      oscillator.stop(startTime + sound.duration);
    }
    
    // æ¸²æŸ“éŸ³é¢‘
    const audioBuffer = await offlineContext.startRendering();
    
    // è½¬æ¢ä¸ºWAV
    const wavBlob = audioBufferToWav(audioBuffer);
    
    // ä¸‹è½½æ–‡ä»¶
    const url = URL.createObjectURL(wavBlob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `drum-recording-${Date.now()}.wav`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
  };

  const audioBufferToWav = (buffer) => {
    const numOfChan = buffer.numberOfChannels;
    const length = buffer.length * numOfChan * 2 + 44;
    const bufferArray = new ArrayBuffer(length);
    const view = new DataView(bufferArray);
    const channels = [];
    let offset = 0;
    let pos = 0;

    // WAVæ–‡ä»¶å¤´
    const setUint16 = (data) => {
      view.setUint16(pos, data, true);
      pos += 2;
    };
    const setUint32 = (data) => {
      view.setUint32(pos, data, true);
      pos += 4;
    };

    // RIFFæ ‡è¯†ç¬¦
    setUint32(0x46464952); // "RIFF"
    setUint32(length - 8); // æ–‡ä»¶å¤§å°
    setUint32(0x45564157); // "WAVE"

    // fmtå­å—
    setUint32(0x20746d66); // "fmt "
    setUint32(16); // å­å—å¤§å°
    setUint16(1); // éŸ³é¢‘æ ¼å¼ (PCM)
    setUint16(numOfChan); // å£°é“æ•°
    setUint32(buffer.sampleRate); // é‡‡æ ·ç‡
    setUint32(buffer.sampleRate * 2 * numOfChan); // å­—èŠ‚ç‡
    setUint16(numOfChan * 2); // å—å¯¹é½
    setUint16(16); // ä½æ·±åº¦

    // dataå­å—
    setUint32(0x61746164); // "data"
    setUint32(length - pos - 4); // æ•°æ®å¤§å°

    // å†™å…¥éŸ³é¢‘æ•°æ®
    for (let i = 0; i < buffer.numberOfChannels; i++) {
      channels.push(buffer.getChannelData(i));
    }

    while (pos < length) {
      for (let i = 0; i < numOfChan; i++) {
        let sample = Math.max(-1, Math.min(1, channels[i][offset]));
        sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
        view.setInt16(pos, sample, true);
        pos += 2;
      }
      offset++;
    }

    return new Blob([bufferArray], { type: 'audio/wav' });
  };

  const handleDrumClick = (drumId) => {
    playSound(drumId);
    const element = document.getElementById(drumId);
    element.classList.add('active');
    setTimeout(() => element.classList.remove('active'), 100);
  };

  const toggleRecording = () => {
    if (!isRecording) {
      setRecordedBeats([]);
      recordingStartTime.current = Date.now();
      setIsRecording(true);
    } else {
      setIsRecording(false);
    }
  };

  const playRecording = () => {
    if (recordedBeats.length === 0 || isPlaying) return;
    
    setIsPlaying(true);
    recordedBeats.forEach(beat => {
      setTimeout(() => {
        playSound(beat.drumId);
        const element = document.getElementById(beat.drumId);
        element.classList.add('active');
        setTimeout(() => element.classList.remove('active'), 100);
      }, beat.timestamp);
    });

    const lastBeat = recordedBeats[recordedBeats.length - 1];
    setTimeout(() => setIsPlaying(false), lastBeat.timestamp + 500);
  };

  const startMetronome = () => {
    const interval = (60 / bpm) * 1000;
    metronomeInterval.current = setInterval(() => {
      const audioContext = new AudioContext();
      const oscillator = audioContext.createOscillator();
      const gainNode = audioContext.createGain();

      oscillator.frequency.value = 1000;
      oscillator.type = 'sine';
      gainNode.gain.setValueAtTime(0.1, audioContext.currentTime);
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.05);

      oscillator.connect(gainNode);
      gainNode.connect(audioContext.destination);
      oscillator.start();
      oscillator.stop(audioContext.currentTime + 0.05);
    }, interval);
  };

  const toggleMetronome = () => {
    if (!metronomeActive) {
      startMetronome();
      setMetronomeActive(true);
    } else {
      clearInterval(metronomeInterval.current);
      setMetronomeActive(false);
    }
  };

  useEffect(() => {
    if (metronomeActive) {
      clearInterval(metronomeInterval.current);
      startMetronome();
    }
  }, [bpm]);

  useEffect(() => {
    const handleKeyPress = (e) => {
      const drum = drums.find(d => d.key.toLowerCase() === e.key.toLowerCase());
      if (drum) {
        handleDrumClick(drum.id);
      }
    };

    window.addEventListener('keydown', handleKeyPress);
    return () => {
      window.removeEventListener('keydown', handleKeyPress);
      if (metronomeInterval.current) clearInterval(metronomeInterval.current);
    };
  }, [isRecording]);

  return (
    <div className="drumkit-container">
      <div className="window-96">
        <div className="window-title-bar">
          <span>ğŸ¥ Virtual Drum Kit v1.0</span>
          <button className="close-btn" onClick={() => navigate('/')}>Ã—</button>
        </div>

        <div className="window-content">
          <div className="controls-panel">
            <div className="control-group">
              <button 
                className={`control-btn ${isRecording ? 'recording' : ''}`}
                onClick={toggleRecording}
              >
                {isRecording ? 'â¹ åœæ­¢å½•éŸ³' : 'âº å¼€å§‹å½•éŸ³'}
              </button>
              
              <button 
                className="control-btn"
                onClick={playRecording}
                disabled={recordedBeats.length === 0 || isPlaying || isExporting}
              >
                {isPlaying ? 'â–¶ æ’­æ”¾ä¸­...' : `â–¶ å›æ”¾ (${recordedBeats.length})`}
              </button>

              <button 
                className={`control-btn ${metronomeActive ? 'active' : ''}`}
                onClick={toggleMetronome}
              >
                {metronomeActive ? 'â¸ èŠ‚æ‹å™¨' : 'ğŸµ èŠ‚æ‹å™¨'}
              </button>

              <button 
                className="control-btn export-btn"
                onClick={exportRecording}
                disabled={recordedBeats.length === 0 || isExporting || isPlaying}
              >
                {isExporting ? 'â³ å¯¼å‡ºä¸­...' : 'ğŸ’¾ å¯¼å‡ºå½•éŸ³'}
              </button>
            </div>

            <div className="control-group">
              <label>BPM: {bpm}</label>
              <input 
                type="range" 
                min="60" 
                max="200" 
                value={bpm}
                onChange={(e) => setBpm(Number(e.target.value))}
                className="bpm-slider"
              />
            </div>

            <div className="control-group">
              <label>å¯¼å‡ºæ ¼å¼:</label>
              <select 
                value={exportFormat} 
                onChange={(e) => setExportFormat(e.target.value)}
                className="format-select"
                disabled={isExporting}
              >
                <option value="webm">WebM (æ¨è)</option>
                <option value="wav">WAV (æ— æŸ)</option>
                <option value="ogg">OGG (å…¼å®¹)</option>
              </select>
            </div>
          </div>

          <div className="drum-grid">
            {drums.map((drum) => (
              <div
                key={drum.id}
                id={drum.id}
                className="drum-pad"
                style={{ borderColor: drum.color }}
                onClick={() => handleDrumClick(drum.id)}
              >
                <div className="drum-name">{drum.name}</div>
                <div className="drum-key">{drum.key}</div>
              </div>
            ))}
          </div>

          <div className="keyboard-hint">
            æŒ‰ä¸‹é”®ç›˜ A-K é”®æ¼”å¥é¼“ç»„
          </div>
        </div>
      </div>
    </div>
  );
}

export default DrumKit;
